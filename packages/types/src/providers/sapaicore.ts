import type { ModelInfo } from "../model.js"

export type SapAiCoreModelId = keyof typeof sapAiCoreModels

export const sapAiCoreDefaultModelId: SapAiCoreModelId = "anthropic--claude-3.5-sonnet"

export const sapAiCoreModels = {
	// Anthropic models
	"anthropic--claude-4-sonnet": {
		maxTokens: 8192,
		contextWindow: 2000000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 5.0,
		outputPrice: 15.0,
		cacheReadsPrice: 0.5,
		cacheWritesPrice: 7.5,
	},
	"anthropic--claude-4-opus": {
		maxTokens: 8192,
		contextWindow: 2000000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 20.0,
		outputPrice: 60.0,
		cacheReadsPrice: 2.0,
		cacheWritesPrice: 30.0,
	},
	"anthropic--claude-3.7-sonnet": {
		maxTokens: 8192,
		contextWindow: 1000000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 3.0,
		outputPrice: 15.0,
		cacheReadsPrice: 0.3,
		cacheWritesPrice: 4.5,
	},
	"anthropic--claude-3.5-sonnet": {
		maxTokens: 8192,
		contextWindow: 200000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 3.0,
		outputPrice: 15.0,
	},
	"anthropic--claude-3-sonnet": {
		maxTokens: 4096,
		contextWindow: 200000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 3.0,
		outputPrice: 15.0,
	},
	"anthropic--claude-3-haiku": {
		maxTokens: 4096,
		contextWindow: 200000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0.25,
		outputPrice: 1.25,
	},
	"anthropic--claude-3-opus": {
		maxTokens: 4096,
		contextWindow: 200000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 15.0,
		outputPrice: 75.0,
	},
	// OpenAI models
	"gpt-4o": {
		maxTokens: 16384,
		contextWindow: 128000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 5.0,
		outputPrice: 15.0,
	},
	"gpt-4": {
		maxTokens: 8192,
		contextWindow: 8192,
		supportsImages: false,
		supportsPromptCache: false,
		inputPrice: 30.0,
		outputPrice: 60.0,
	},
	"gpt-4o-mini": {
		maxTokens: 16384,
		contextWindow: 128000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0.15,
		outputPrice: 0.6,
	},
	o1: {
		maxTokens: 100000,
		contextWindow: 200000,
		supportsImages: false,
		supportsPromptCache: false,
		inputPrice: 15.0,
		outputPrice: 60.0,
	},
	"gpt-4.1": {
		maxTokens: 32768,
		contextWindow: 128000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 5.0,
		outputPrice: 15.0,
	},
	"gpt-4.1-nano": {
		maxTokens: 16384,
		contextWindow: 128000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0.15,
		outputPrice: 0.6,
	},
	"gpt-5": {
		maxTokens: 32768,
		contextWindow: 256000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 10.0,
		outputPrice: 30.0,
	},
	"gpt-5-nano": {
		maxTokens: 16384,
		contextWindow: 256000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0.5,
		outputPrice: 1.5,
	},
	"gpt-5-mini": {
		maxTokens: 16384,
		contextWindow: 256000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 1.0,
		outputPrice: 3.0,
	},
	"o3-mini": {
		maxTokens: 100000,
		contextWindow: 200000,
		supportsImages: false,
		supportsPromptCache: false,
		inputPrice: 1.0,
		outputPrice: 4.0,
	},
	o3: {
		maxTokens: 100000,
		contextWindow: 200000,
		supportsImages: false,
		supportsPromptCache: false,
		inputPrice: 60.0,
		outputPrice: 240.0,
	},
	"o4-mini": {
		maxTokens: 100000,
		contextWindow: 200000,
		supportsImages: false,
		supportsPromptCache: false,
		inputPrice: 2.0,
		outputPrice: 8.0,
	},
	// Gemini models
	"gemini-2.5-flash": {
		maxTokens: 8192,
		contextWindow: 1000000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0.5,
		outputPrice: 1.5,
		maxThinkingTokens: 32768,
	},
	"gemini-2.5-pro": {
		maxTokens: 8192,
		contextWindow: 2000000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 2.5,
		outputPrice: 10.0,
		maxThinkingTokens: 65536,
	},
} satisfies Record<string, ModelInfo>
