# ğŸ¢ Roo Code On-Premises Setup Guide\n\n## ê°œìš”\n\nRoo Code ì˜¨í”„ë ˆë¯¸ìŠ¤ ì—ë””ì…˜ì€ ê¸°ì—… í™˜ê²½ì—ì„œ 100% ì˜¤í”„ë¼ì¸ìœ¼ë¡œ ì‘ë™í•˜ë„ë¡ ì„¤ê³„ëœ VS Code í™•ì¥ì…ë‹ˆë‹¤. ì™¸ë¶€ API í˜¸ì¶œ ì°¨ë‹¨, í…”ë ˆë©”íŠ¸ë¦¬ ë¹„í™œì„±í™”, ë¡œì»¬ LLM ì§€ì›ì„ í†µí•´ ì™„ì „í•œ ê²©ë¦¬ í™˜ê²½ì—ì„œ AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n## ğŸ”‘ ì£¼ìš” ê¸°ëŠ¥\n\n### âœ… ì™„ì „í•œ ì˜¤í”„ë¼ì¸ ì§€ì›\n- **ì™¸ë¶€ API ì°¨ë‹¨**: ëª¨ë“  í´ë¼ìš°ë“œ API í˜¸ì¶œ ìë™ ì°¨ë‹¨\n- **í…”ë ˆë©”íŠ¸ë¦¬ ë¹„í™œì„±í™”**: ì‚¬ìš© ë°ì´í„° ìˆ˜ì§‘ ì™„ì „ ë¹„í™œì„±í™” \n- **ë¡œì»¬ LLM í†µí•©**: vLLM, Ollama ì§€ì›\n- **ê¸°ì—… ë„¤íŠ¸ì›Œí¬ í˜¸í™˜**: ë°©í™”ë²½ í™˜ê²½ì—ì„œ ì™„ì „ ì‘ë™\n\n### ğŸ›¡ï¸ ë³´ì•ˆ ê¸°ëŠ¥\n- HTTP/HTTPS ìš”ì²­ ì°¨ë‹¨ ë° ëª¨ë‹ˆí„°ë§\n- ì˜¨í”„ë ˆë¯¸ìŠ¤ ëª¨ë“œ ìë™ ê°ì§€ (`ON_PREM=true`)\n- ë¡œì»¬ LLM ì„œë²„ ì—°ê²° ê²€ì¦\n- ë„¤íŠ¸ì›Œí¬ ê²©ë¦¬ í…ŒìŠ¤íŠ¸ í¬í•¨\n\n## ğŸ“‹ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­\n\n### ìµœì†Œ ìš”êµ¬ì‚¬í•­\n- **VS Code**: 1.84.0 ì´ìƒ\n- **Node.js**: 20.19.2\n- **ë©”ëª¨ë¦¬**: 4GB RAM ì´ìƒ\n- **ë””ìŠ¤í¬**: 200MB ì—¬ìœ  ê³µê°„\n\n### ë¡œì»¬ LLM ì„œë²„ (ì„ íƒì‚¬í•­)\n- **vLLM ì„œë²„**: GPU ì§€ì› ê¶Œì¥\n- **Ollama**: CPU/GPU ëª¨ë‘ ì§€ì›\n- **ë„¤íŠ¸ì›Œí¬**: ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ ì ‘ê·¼ í•„ìš”\n\n## ğŸš€ ì„¤ì¹˜ ë°©ë²•\n\n### 1. VSIX íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n\nìµœì‹  ì˜¨í”„ë ˆë¯¸ìŠ¤ ì—ë””ì…˜ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:\n\n`bash\n# GitHub Releasesì—ì„œ ë‹¤ìš´ë¡œë“œ\nwget https://github.com/RooCodeInc/Roo-Code/releases/latest/download/roo-cline-onprem-latest.vsix\n`\n\n### 2. VS Codeì— ì„¤ì¹˜\n\n#### ë°©ë²• 1: ëª…ë ¹ì¤„ ì„¤ì¹˜\n`bash\ncode --install-extension roo-cline-onprem-3.22.6-onprem.1.vsix\n`\n\n#### ë°©ë²• 2: VS Code UI ì„¤ì¹˜\n1. VS Code ì—´ê¸°\n2. `Ctrl+Shift+P` (ë˜ëŠ” `Cmd+Shift+P`)\n3. \"Extensions: Install from VSIX...\" ì„ íƒ\n4. VSIX íŒŒì¼ ì„ íƒ\n\n### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n\nì˜¨í”„ë ˆë¯¸ìŠ¤ ëª¨ë“œë¥¼ í™œì„±í™”í•˜ë ¤ë©´:\n\n`bash\n# Linux/macOS\nexport ON_PREM=true\n\n# Windows\nset ON_PREM=true\n\n# PowerShell\n$env:ON_PREM=\"true\"\n`\n\në˜ëŠ” VS Code ì„¤ì •ì—ì„œ:\n\n`json\n{\n  \"terminal.integrated.env.linux\": {\n    \"ON_PREM\": \"true\"\n  },\n  \"terminal.integrated.env.osx\": {\n    \"ON_PREM\": \"true\"\n  },\n  \"terminal.integrated.env.windows\": {\n    \"ON_PREM\": \"true\"\n  }\n}\n`\n\n## ğŸ¤– ë¡œì»¬ LLM ì„¤ì •\n\n### vLLM ì„œë²„ ì„¤ì •\n\n#### 1. vLLM ì„¤ì¹˜\n`bash\npip install vllm\n`\n\n#### 2. ì„œë²„ ì‹œì‘\n`bash\npython -m vllm.entrypoints.openai.api_server \\\n  --model microsoft/DialoGPT-medium \\\n  --host 0.0.0.0 \\\n  --port 8000\n`\n\n#### 3. VS Code ì„¤ì •\n`json\n{\n  \"rooCode.localLLM.enabled\": true,\n  \"rooCode.localLLM.type\": \"vllm\",\n  \"rooCode.localLLM.vllm.endpoint\": \"http://localhost:8000\",\n  \"rooCode.localLLM.vllm.modelName\": \"microsoft/DialoGPT-medium\",\n  \"rooCode.localLLM.fallbackToCloud\": false\n}\n`\n\n### Ollama ì„œë²„ ì„¤ì •\n\n#### 1. Ollama ì„¤ì¹˜\n`bash\n# Linux\ncurl -fsSL https://ollama.ai/install.sh | sh\n\n# macOS\nbrew install ollama\n\n# Windows\nwinget install Ollama.Ollama\n`\n\n#### 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì‹¤í–‰\n`bash\n# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\nollama pull llama2\n\n# ì„œë²„ ì‹œì‘\nollama serve\n`\n\n#### 3. VS Code ì„¤ì •\n`json\n{\n  \"rooCode.localLLM.enabled\": true,\n  \"rooCode.localLLM.type\": \"ollama\",\n  \"rooCode.localLLM.ollama.endpoint\": \"http://localhost:11434\",\n  \"rooCode.localLLM.ollama.modelName\": \"llama2\",\n  \"rooCode.localLLM.fallbackToCloud\": false\n}\n`\n\n## âš™ï¸ ê³ ê¸‰ ì„¤ì •\n\n### ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ ì„¤ì •\n\n`json\n{\n  \"rooCode.onPrem.blockExternalRequests\": true,\n  \"rooCode.onPrem.allowedDomains\": [\n    \"localhost\",\n    \"127.0.0.1\",\n    \"internal-llm-server.company.com\"\n  ],\n  \"rooCode.onPrem.logBlockedRequests\": true\n}\n`\n\n### í…”ë ˆë©”íŠ¸ë¦¬ ì™„ì „ ë¹„í™œì„±í™”\n\n`json\n{\n  \"rooCode.telemetry.enabled\": false,\n  \"rooCode.onPrem.blockTelemetry\": true,\n  \"telemetry.telemetryLevel\": \"off\"\n}\n`\n\n### ë¡œì»¬ LLM ì„±ëŠ¥ ì¡°ì •\n\n`json\n{\n  \"rooCode.localLLM.maxTokens\": 2048,\n  \"rooCode.localLLM.temperature\": 0.7,\n  \"rooCode.localLLM.timeout\": 30,\n  \"rooCode.localLLM.requestQueue.maxConcurrent\": 3,\n  \"rooCode.localLLM.requestQueue.retryAttempts\": 2\n}\n`\n\n## ğŸ” ë¬¸ì œ í•´ê²°\n\n### ì¼ë°˜ì ì¸ ë¬¸ì œ\n\n#### 1. ì˜¨í”„ë ˆë¯¸ìŠ¤ ëª¨ë“œê°€ í™œì„±í™”ë˜ì§€ ì•ŠìŒ\n\n**ì¦ìƒ**: í´ë¼ìš°ë“œ API í˜¸ì¶œì´ ê³„ì† ë°œìƒ\n\n**í•´ê²°ì±…**:\n`bash\n# í™˜ê²½ ë³€ìˆ˜ í™•ì¸\necho $ON_PREM  # Linux/macOS\necho %ON_PREM%  # Windows CMD\necho $env:ON_PREM  # PowerShell\n\n# VS Code ì¬ì‹œì‘\ncode --reload-extensions\n`\n\n#### 2. ë¡œì»¬ LLM ì—°ê²° ì‹¤íŒ¨\n\n**ì¦ìƒ**: \"Local LLM server connection failed\"\n\n**í•´ê²°ì±…**:\n`bash\n# ì„œë²„ ìƒíƒœ í™•ì¸\ncurl http://localhost:8000/health  # vLLM\ncurl http://localhost:11434/api/tags  # Ollama\n\n# ë°©í™”ë²½ ê·œì¹™ í™•ì¸\nsudo ufw allow 8000  # vLLM\nsudo ufw allow 11434  # Ollama\n`\n\n#### 3. ì„±ëŠ¥ ë¬¸ì œ\n\n**ì¦ìƒ**: ì‘ë‹µ ì†ë„ ëŠë¦¼\n\n**í•´ê²°ì±…**:\n`json\n{\n  \"rooCode.localLLM.timeout\": 60,\n  \"rooCode.localLLM.maxTokens\": 1024,\n  \"rooCode.localLLM.requestQueue.maxConcurrent\": 1\n}\n`\n\n### ë¡œê·¸ í™•ì¸\n\n#### 1. í™•ì¥ ë¡œê·¸\n- `Ctrl+Shift+P` â†’ \"Developer: Show Logs\" â†’ \"Extension Host\"\n\n#### 2. ë„¤íŠ¸ì›Œí¬ ì°¨ë‹¨ ë¡œê·¸\n`bash\n# ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜\n# macOS: ~/Library/Application Support/Code/logs/\n# Linux: ~/.config/Code/logs/\n# Windows: %APPDATA%\\Code\\logs\\\n\ntail -f \"$HOME/.config/Code/logs/renderer1.log\" | grep \"BLOCKED\"\n`\n\n## ğŸ§ª ê²€ì¦ í…ŒìŠ¤íŠ¸\n\n### 1. ì˜¨í”„ë ˆë¯¸ìŠ¤ ëª¨ë“œ í™•ì¸\n\n`javascript\n// VS Code ê°œë°œì ì½˜ì†”ì—ì„œ ì‹¤í–‰\nconsole.log('ON_PREM mode:', process.env.ON_PREM);\n`\n\n### 2. ì™¸ë¶€ ìš”ì²­ ì°¨ë‹¨ í…ŒìŠ¤íŠ¸\n\n`bash\n# ê°œë°œì ë„êµ¬ > ë„¤íŠ¸ì›Œí¬ íƒ­ì—ì„œ í™•ì¸\n# api.openai.com, api.anthropic.com ë“±ìœ¼ë¡œì˜ ìš”ì²­ì´ ì°¨ë‹¨ë˜ëŠ”ì§€ í™•ì¸\n`\n\n### 3. ë¡œì»¬ LLM ì—°ê²° í…ŒìŠ¤íŠ¸\n\n`bash\n# VS Code ëª…ë ¹ íŒ”ë ˆíŠ¸ì—ì„œ\n# \"Roo Code: Test Local LLM Connection\" ì‹¤í–‰\n`\n\n## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤\n\n- [vLLM ë¬¸ì„œ](https://vllm.readthedocs.io/)\n- [Ollama ë¬¸ì„œ](https://ollama.ai/docs)\n- [Roo Code GitHub](https://github.com/RooCodeInc/Roo-Code)\n- [ì´ìŠˆ ì‹ ê³ ](https://github.com/RooCodeInc/Roo-Code/issues)\n\n## ğŸ“ ì§€ì›\n\nê¸°ì—… ì§€ì›ì´ í•„ìš”í•˜ì‹œë©´:\n- ğŸ“§ Email: enterprise@roocode.io\n- ğŸ’¬ Slack: [Roo Code Enterprise](https://roocode.slack.com)\n- ğŸ“ Phone: +1-555-ROO-CODE\n\n---\n\n**âš ï¸ ì¤‘ìš”**: ì˜¨í”„ë ˆë¯¸ìŠ¤ ëª¨ë“œì—ì„œëŠ” í´ë¼ìš°ë“œ ê¸°ë°˜ ê¸°ëŠ¥(Claude, ChatGPT ë“±)ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤. ëª¨ë“  AI ê¸°ëŠ¥ì€ ë¡œì»¬ LLM ì„œë²„ë¥¼ í†µí•´ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤.
