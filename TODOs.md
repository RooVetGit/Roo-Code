# TODOs.md

## ğŸ” 1. ì½”ë“œ/ì˜ì¡´ì„± ì¡°ì‚¬ âœ…

- [x] `grep "http"` â†’ ì™¸ë¶€ URL ëª©ë¡í™” (`scripts/detect-outbound.ts` êµ¬í˜„ ì™„ë£Œ)
- [x] Telemetry ëª¨ë“ˆ(`src/analytics/*`) ë¶„ë¦¬ (`OnPremTelemetryClient` êµ¬í˜„ ì™„ë£Œ)
- [x] ëª¨ë“œ ë§ˆì¼“í”Œë ˆì´ìŠ¤ í˜¸ì¶œ ê²½ë¡œ íŒŒì•… (`fetch-wrapper.ts`ë¡œ ì°¨ë‹¨ êµ¬í˜„)

## ğŸ› ï¸ 2. Telemetry ì°¨ë‹¨ âœ…

- [x] `ON_PREM` env flag ë„ì… (`fetch-wrapper.ts` êµ¬í˜„ ì™„ë£Œ)
- [x] flag ON ì‹œ `fetch` wrapper â†’ no-op (ì™„ì „ êµ¬í˜„ë¨)
- [x] CI: `npm run detect-outbound` ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€ (package.jsonì— ì¶”ê°€ë¨)

## ğŸ¤– 3. Local LLM(vLLM, Ollama) ì§€ì› âœ…

- [x] `settings.schema.json`ì— `localLLM.type`(`vllm` | `ollama`) & `localLLM.url` (package.jsonì— ì™„ì „ êµ¬í˜„)
- [x] vLLM ì˜ˆì œ config (`http://gpu-srv:1234/v1/chat/completions`) (VLLMHandler êµ¬í˜„ ì™„ë£Œ)
- [x] vLLM vs Ollama ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸ (`scripts/benchmark-local-llm.ts`) (npm ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€ë¨)
- [x] ìš”ì²­/ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ê³µí†µ ì–´ëŒ‘í„° êµ¬í˜„ (VLLMHandler, OllamaHandler ëª¨ë‘ êµ¬í˜„ë¨)
- [x] `localLLMProvider.ts` ìœ í‹¸ë¦¬í‹° ì™„ì„± (config ì½ê¸°, ì—°ê²° ê²€ì¦, ìë™ ì „í™˜)

## ğŸ§ª 4. í…ŒìŠ¤íŠ¸ âœ…

- [x] Jest unit test > outbound mock (fetch-wrapper, OnPremTelemetryClient, localLLMProvider í…ŒìŠ¤íŠ¸ ì™„ë£Œ)
- [x] Playwright e2e > ì˜¤í”„ë¼ì¸ í™˜ê²½ + vLLM í†µí•© ì‹œë‚˜ë¦¬ì˜¤ (tests/e2e/on-prem-vllm.spec.ts êµ¬í˜„)
- [x] íŒŒì´ì–´ì›” í…ŒìŠ¤íŠ¸ Docker Compose (tests/firewall/ í™˜ê²½ êµ¬í˜„, npm run test:firewall:docker)
- [x] Integration í…ŒìŠ¤íŠ¸ (`src/__tests__/integration/on-prem-integration.spec.ts`)

## ğŸ“¦ 5. ë¹Œë“œ/ë°°í¬ âœ…

- [x] `package.json` í•„ë“œ ê²€í† : `publisher`, `name`, `version`, `engines.vscode` (src/package.onprem.json ìƒì„±)
- [x] ì˜¨í”„ë ˆë¯¸ìŠ¤ìš© ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (`scripts/build-onprem.mjs`)
- [x] `npm run package:onprem` ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€ ë° VSIX ìƒì„± í…ŒìŠ¤íŠ¸ â†’ 16.72MB ì„±ê³µ
- [x] turbo.jsonì— onprem ë¹Œë“œ íƒœìŠ¤í¬ ì¶”ê°€ (`bundle:onprem`, `vsix:onprem`)
- [x] GitLab CI íŒŒì´í”„ë¼ì¸ ì™„ì„± (`.gitlab-ci.yml`) - validate, test, build, package, deploy ë‹¨ê³„

## ğŸ“š 6. ë¬¸ì„œí™” âœ…

- [x] `docs/on-prem-setup.md` ì™„ì„± - VSIX ì„¤ì¹˜ ë°©ë²•(`code --install-extension <your>.vsix`) í¬í•¨
- [x] ë¡œì»¬ LLM ì„¤ì • ê°€ì´ë“œ (vLLM, Ollama êµ¬ì²´ì  ì„¤ì •ë²•)
- [x] í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (`ON_PREM=true`)
- [x] ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ë° ê²€ì¦ í…ŒìŠ¤íŠ¸ ë°©ë²•
- [x] ë²ˆì—­ íŒŒì¼ ì—…ë°ì´íŠ¸ (`src/package.nls.json`)

## âœ… 7. ê²€í† Â·ë¦´ë¦¬ìŠ¤

- [ ] ë³´ì•ˆíŒ€ ì½”ë“œ ë¦¬ë·°
- [ ] ì‚¬ë‚´ í…ŒìŠ¤íŠ¸ë² ë“œ ë°°í¬ (vLLM ì„œë²„ ì—°ë™ + VSIX ì„¤ì¹˜ ê²€ì¦)
- [ ] v0.1-onprem Tag & ë‚´ë¶€ NPM/Nexus Registry ì—…ë¡œë“œ

---

## ğŸ¯ **í”„ë¡œì íŠ¸ ì™„ì„±ë„: 85% (17/20 í•­ëª© ì™„ë£Œ)**

### âœ… **ì™„ë£Œëœ ì£¼ìš” ê¸°ëŠ¥:**

- **100% ì˜¤í”„ë¼ì¸ ì‘ë™**: ëª¨ë“  ì™¸ë¶€ API í˜¸ì¶œ ì°¨ë‹¨ (`fetch-wrapper.ts`)
- **í…”ë ˆë©”íŠ¸ë¦¬ ì™„ì „ ë¹„í™œì„±í™”**: `OnPremTelemetryClient`
- **ë¡œì»¬ LLM í†µí•©**: vLLM/Ollama ìë™ ê°ì§€ ë° ì „í™˜
- **í¬ê´„ì  í…ŒìŠ¤íŠ¸**: Unit/Integration/E2E/Docker ë°©í™”ë²½ í…ŒìŠ¤íŠ¸
- **VSIX íŒ¨í‚¤ì§•**: `roo-cline-onprem-3.22.6-onprem.1.vsix` (16.72MB)
- **CI/CD íŒŒì´í”„ë¼ì¸**: GitLab ìë™í™” ë¹Œë“œ/ë°°í¬
- **ì™„ì „í•œ ë¬¸ì„œí™”**: ì„¤ì¹˜/ì„¤ì •/ë¬¸ì œí•´ê²° ê°€ì´ë“œ

### ğŸš€ **ë°°í¬ ì¤€ë¹„ ì™„ë£Œ:**

```bash
# ì„¤ì¹˜ ëª…ë ¹ì–´
code --install-extension bin/roo-cline-onprem-3.22.6-onprem.1.vsix

# ì˜¨í”„ë ˆë¯¸ìŠ¤ ëª¨ë“œ í™œì„±í™”
export ON_PREM=true
```

### ğŸ“‹ **ë‚¨ì€ ì‘ì—…:**

- ë³´ì•ˆíŒ€ ì½”ë“œ ë¦¬ë·°
- ì‚¬ë‚´ í…ŒìŠ¤íŠ¸ë² ë“œ ê²€ì¦
- ì •ì‹ ë¦´ë¦¬ìŠ¤ íƒœê¹…
